{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T20:13:03.534181Z",
     "start_time": "2020-04-07T20:13:03.525782Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#v2\n",
    "#7/11/2018\n",
    "\n",
    "dataname=\"bladder_te_filt\"\n",
    "\n",
    "desired_mask_mpp = 16\n",
    "model_mpp = 0.5 # MPP of patches to be fed into model\n",
    "\n",
    "patch_size=256 #size of the tiles to extract and save in the database, must be >= to training size\n",
    "stride_size = patch_size\n",
    "test_set_size=.2 # what percentage of the dataset should be used as a held out validation/testing set\n",
    "resize=1 #resize input images\n",
    "class_names=[0,1] #what classes we expect to have in the data, here we have only 2 classes but we could add additional classes and/or specify an index from which we would like to ignore\n",
    "\n",
    "#-----Note---\n",
    "#One should likely make sure that  (nrow+mirror_pad_size) mod patch_size == 0, where nrow is the number of rows after resizing\n",
    "#so that no pixels are lost (any remainer is ignored)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T20:13:05.032221Z",
     "start_time": "2020-04-07T20:13:03.537828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed (note down for reproducibility): 798764965297604225\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tables\n",
    "\n",
    "import os,sys\n",
    "import glob\n",
    "\n",
    "import PIL\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import model_selection\n",
    "import sklearn.feature_extraction.image\n",
    "import random\n",
    "\n",
    "sys.path.insert(1,'/mnt/data/home/pjl54/WSI_handling')\n",
    "import wsi\n",
    "\n",
    "import tqdm\n",
    "\n",
    "seed = random.randrange(sys.maxsize) #get a random seed so that we can reproducibly do the cross validation setup\n",
    "random.seed(seed) # set the seed\n",
    "print(f\"random seed (note down for reproducibility): {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T20:13:07.857360Z",
     "start_time": "2020-04-07T20:13:05.035846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (down_path): ModuleList(\n",
       "    (0): UNetConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): ReLU()\n",
       "        (5): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): UNetConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): ReLU()\n",
       "        (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): UNetConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): ReLU()\n",
       "        (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): UNetConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): ReLU()\n",
       "        (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_path): ModuleList(\n",
       "    (0): UNetUpBlock(\n",
       "      (up): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv_block): UNetConvBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): UNetUpBlock(\n",
       "      (up): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv_block): UNetConvBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): UNetUpBlock(\n",
       "      (up): ConvTranspose2d(16, 8, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv_block): UNetConvBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (last): Conv2d(8, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unet import UNet\n",
    "\n",
    "te_model = '/mnt/data/home/pjl54/bladder/bladderTE_1mpp_256p.pth'\n",
    "te_mpp = 1;\n",
    "te_device = 2\n",
    "checkpoint = torch.load(te_model, map_location=lambda storage, loc: storage) #load checkpoint to CPU and then put to device https://discuss.pytorch.org/t/saving-and-loading-torch-models-on-2-machines-with-different-number-of-gpu-devices/6666\n",
    "model = UNet(n_classes=checkpoint[\"n_classes\"], in_channels=checkpoint[\"in_channels\"],\n",
    "             padding=checkpoint[\"padding\"], depth=checkpoint[\"depth\"], wf=checkpoint[\"wf\"],\n",
    "             up_mode=checkpoint[\"up_mode\"], batch_norm=checkpoint[\"batch_norm\"]).to(te_device)\n",
    "model.load_state_dict(checkpoint[\"model_dict\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T20:13:07.864454Z",
     "start_time": "2020-04-07T20:13:07.860660Z"
    }
   },
   "outputs": [],
   "source": [
    "img_dtype = tables.UInt8Atom()  # dtype in which the images will be saved, this indicates that images will be saved as unsigned int 8 bit, i.e., [0,255]\n",
    "filenameAtom = tables.StringAtom(itemsize=255) #create an atom to store the filename of the image, just incase we need it later, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T20:13:07.891012Z",
     "start_time": "2020-04-07T20:13:07.866752Z"
    }
   },
   "outputs": [],
   "source": [
    "grade_key = {}\n",
    "with open('/mnt/data/home/pjl54/bladder/densenet/blad_grade_key.txt') as file:\n",
    "    for line in file:\n",
    "        (patient, label) = line.split()\n",
    "        grade_key[patient] = int(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T20:13:08.068167Z",
     "start_time": "2020-04-07T20:13:07.893046Z"
    }
   },
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for patient in grade_key.keys():\n",
    "    if os.path.exists('/mnt/ccipd_data/UH_Bladder_Cancer_Project/Blad170830/' + patient):\n",
    "        all_files.append('/mnt/ccipd_data/UH_Bladder_Cancer_Project/Blad170830/' + patient)\n",
    "    else:\n",
    "        all_files.append('/mnt/ccipd_data/UH_Bladder_Histology/May_2019/Ventana/' + patient)\n",
    "\n",
    "# all_files=glob.glob(r'/mnt/data/home/pjl54/pesoProstateSE/imgs/*training_mask.tif')\n",
    "\n",
    "#create training and validation stages and split the files appropriately between them\n",
    "phases={}\n",
    "phases[\"train\"],phases[\"val\"]=next(iter(model_selection.ShuffleSplit(n_splits=1,test_size=test_set_size).split(all_files)))\n",
    "\n",
    "#specify that we'll be saving 2 different image types to the database, an image and its associated masked\n",
    "imgtypes=[\"imgs\",\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T21:15:57.220049Z",
     "start_time": "2020-04-07T20:13:08.071981Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [40:57, 61.44s/it] \n",
      "40it [08:27, 12.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [10:42, 64.27s/it]\n",
      "10it [02:34, 15.50s/it]\n"
     ]
    }
   ],
   "source": [
    "storage={} #holder for future pytables\n",
    "block_shape= np.array((patch_size,patch_size,3))\n",
    "\n",
    "filters=tables.Filters(complevel=6, complib='zlib') #we can also specify filters, such as compression, to improve storage speed\n",
    "\n",
    "for phase in phases.keys(): #now for each of the phases, we'll loop through the files\n",
    "    print(phase)\n",
    "    files = [all_files[k] for k in phases[phase]]\n",
    "    \n",
    "    rscs = [[] for i in range(0,len(files))]    \n",
    "\n",
    "    osis = [wsi.wsi(img_fname = file, xml_fname = file.split('.tif')[0]+'.xml') for file in files]\n",
    "\n",
    "    totals=np.zeros(len(class_names)) # we can to keep counts of all the classes in for in particular training, since we \n",
    "\n",
    "    hdf5_file = tables.open_file(f\"./{dataname}_{phase}.pytable\", mode='w') #open the respective pytable\n",
    "    storage[\"filenames\"] = hdf5_file.create_earray(hdf5_file.root, 'filenames', filenameAtom, (0,)) #create the array for storage\n",
    "    \n",
    "    storage[\"imgs\"]= hdf5_file.create_earray(hdf5_file.root, \"imgs\", img_dtype,  \n",
    "                                                  shape=np.append([0],block_shape), \n",
    "                                                  chunkshape=np.append([1],block_shape),\n",
    "                                                  filters=filters)\n",
    "\n",
    "    storage[\"labels\"]= hdf5_file.create_earray(hdf5_file.root, \"labels\", img_dtype,  \n",
    "                                              shape=[0], \n",
    "                                              chunkshape=[1],\n",
    "                                              filters=filters)\n",
    "\n",
    "\n",
    "    for index, wsi_img in tqdm.tqdm(enumerate(osis)):        \n",
    "\n",
    "        stride_size_converted = wsi_img.get_coord_at_mpp(stride_size,input_mpp=wsi_img[\"mpps\"][0],output_mpp=desired_mask_mpp)\n",
    "\n",
    "        [mask_small, resize_factor] = wsi_img.mask_out_annotation(desired_mpp=desired_mask_mpp,colors_to_use=None)            \n",
    "\n",
    "        mask_small = mask_small[list(range(0,np.shape(mask_small)[0],stride_size_converted)),:]            \n",
    "        mask_small = mask_small[:,list(range(0,np.shape(mask_small)[1],stride_size_converted))]            \n",
    "\n",
    "        [rs,cs]=(mask_small>0).nonzero()\n",
    "        rs = [r*stride_size_converted for r in rs]\n",
    "        cs = [c*stride_size_converted for c in cs]\n",
    "\n",
    "        rs = [wsi_img.get_coord_at_mpp(r,wsi_img[\"mpps\"][0],desired_mask_mpp) for r in rs]\n",
    "        cs = [wsi_img.get_coord_at_mpp(c,wsi_img[\"mpps\"][0],desired_mask_mpp) for c in cs]\n",
    "\n",
    "        goods = np.ones(np.shape(rs)[0])\n",
    "        for k in range(0,np.shape(rs)[0]):\n",
    "\n",
    "#             a = wsi_img.get_tile(coords=(cs[k],rs[k]),wh=(1,1),desired_mpp=desired_mask_mpp)\n",
    "#             if((np.sum(a>220)/np.size(a))>0.50):                \n",
    "#                 goods[k] = False             \n",
    "#             else:                                \n",
    "            te_tile = wsi_img.get_tile(coords=(cs[k],rs[k]),wh=(int(patch_size*(te_mpp/model_mpp)),int(patch_size*(te_mpp/model_mpp))),desired_mpp=te_mpp)\n",
    "            if((np.sum(te_tile[:,:,1]>220)/np.size(te_tile[:,:,1]))>0.30):\n",
    "                goods[k] = False\n",
    "            else:    \n",
    "                arr_out_gpu = torch.from_numpy(np.expand_dims(te_tile,axis=0).transpose(0,3,1,2) / 255).type('torch.FloatTensor').to(te_device)\n",
    "                output_batch = model(arr_out_gpu)\n",
    "                output = output_batch[0,:,:,:].detach().cpu().numpy()\n",
    "                te_map = output.argmax(axis=0)==1\n",
    "\n",
    "                if((np.sum(te_map)/np.size(te_map))<0.50):                \n",
    "                    goods[k] = False\n",
    "\n",
    "        cs = [c for idx,c in enumerate(cs) if goods[idx]]\n",
    "        rs = [r for idx,r in enumerate(rs) if goods[idx]]\n",
    "        rscs[index]=(cs,rs)            \n",
    "        \n",
    "        classid = grade_key[wsi_img['img_fname'].split('/')[-1]]\n",
    "        totals[classid]+=1\n",
    "\n",
    "\n",
    "    patch_counts = [np.shape(k)[1] for k in rscs]        \n",
    "#     patch_counts[0] = patch_counts[0] - 1   \n",
    "    adds = [1] + patch_counts\n",
    "    adds = np.cumsum(adds)\n",
    "#     storage[\"img\"] = np.ones([sum(patch_counts),patch_size,patch_size,3],dtype=np.uint8)\n",
    "#     storage[\"mask\"] = np.ones([sum(patch_counts),patch_size,patch_size],dtype=np.uint8)\n",
    "\n",
    "    for index, wsi_img in tqdm.tqdm(enumerate(osis)):\n",
    "        img_label = grade_key[wsi_img['img_fname'].split('/')[-1]]\n",
    "        for rcidx in range(0,patch_counts[index]-1):            \n",
    "\n",
    "            img = wsi_img.get_tile(desired_mpp=model_mpp,coords=(rscs[index][0][rcidx],rscs[index][1][rcidx]),wh=(patch_size,patch_size))        \n",
    "\n",
    "\n",
    "            storage[\"imgs\"].append(img.reshape(-1,patch_size,patch_size,3))\n",
    "            storage[\"labels\"].append([img_label])\n",
    "\n",
    "        storage[\"filenames\"].append([files[index] for x in range(patch_counts[index]-1)]) #add the filename to the storage array\n",
    "\n",
    "    #lastely, we should store the number of pixels\n",
    "    npixels=hdf5_file.create_carray(hdf5_file.root, 'classsizes', tables.Atom.from_dtype(totals.dtype), totals.shape)\n",
    "    npixels[:]=totals\n",
    "    hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T21:15:58.380286Z",
     "start_time": "2020-04-07T21:15:57.223351Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ClosedNodeError",
     "evalue": "the node object is closed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClosedNodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-92280bff7475>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"imgs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tables/array.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    651\u001b[0m         \"\"\"\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_check_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tables/node.py\u001b[0m in \u001b[0;36m_g_check_open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v_isopen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mClosedNodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the node object is closed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misopen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"found an open node in a closed file\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClosedNodeError\u001b[0m: the node object is closed"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for k in range(1,500,50):\n",
    "    fig, ax = plt.subplots(1,3,figsize=(20,20))\n",
    "    ax[0].imshow(storage[\"imgs\"][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T21:15:58.382534Z",
     "start_time": "2020-04-07T20:13:01.543Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "storage={} #holder for future pytables\n",
    "block_shape= np.array((patch_size,patch_size,3))\n",
    "\n",
    "filters=tables.Filters(complevel=6, complib='zlib') #we can also specify filters, such as compression, to improve storage speed\n",
    "\n",
    "for phase in phases.keys(): #now for each of the phases, we'll loop through the files\n",
    "    print(phase)\n",
    "    files = [all_files[k] for k in phases[phase]]\n",
    "    \n",
    "    rscs = [[] for i in range(0,len(files))]    \n",
    "\n",
    "    osis = [wsi.wsi(img_fname = file, xml_fname = file.split('.tif')[0]+'.xml') for file in files]\n",
    "\n",
    "    totals=np.zeros(len(class_names)) # we can to keep counts of all the classes in for in particular training, since we \n",
    "\n",
    "    for index, wsi_img in tqdm.tqdm(enumerate(osis)):        \n",
    "\n",
    "        stride_size_converted = wsi_img.get_coord_at_mpp(stride_size,input_mpp=wsi_img[\"mpps\"][0],output_mpp=desired_mask_mpp)\n",
    "\n",
    "        [mask_small, resize_factor] = wsi_img.mask_out_annotation(desired_mpp=desired_mask_mpp,colors_to_use=None)            \n",
    "\n",
    "        mask_small = mask_small[list(range(0,np.shape(mask_small)[0],stride_size_converted)),:]            \n",
    "        mask_small = mask_small[:,list(range(0,np.shape(mask_small)[1],stride_size_converted))]            \n",
    "\n",
    "        [rs,cs]=(mask_small>0).nonzero()\n",
    "        rs = [r*stride_size_converted for r in rs]\n",
    "        cs = [c*stride_size_converted for c in cs]\n",
    "\n",
    "        rs = [wsi_img.get_coord_at_mpp(r,wsi_img[\"mpps\"][0],desired_mask_mpp) for r in rs]\n",
    "        cs = [wsi_img.get_coord_at_mpp(c,wsi_img[\"mpps\"][0],desired_mask_mpp) for c in cs]\n",
    "\n",
    "        goods = np.ones(np.shape(rs)[0])\n",
    "        for k in range(0,np.shape(rs)[0]):\n",
    "\n",
    "            a = wsi_img.get_tile(coords=(cs[k],rs[k]),wh=(1,1),desired_mpp=desired_mask_mpp)\n",
    "            if(np.all(a>220)):\n",
    "                goods[k] = False             \n",
    "\n",
    "        cs = [c for idx,c in enumerate(cs) if goods[idx]]\n",
    "        rs = [r for idx,r in enumerate(rs) if goods[idx]]\n",
    "        rscs[index]=(cs,rs)            \n",
    "        \n",
    "        classid = grade_key[wsi_img['img_fname'].split('/')[-1]]\n",
    "        totals[classid]+=1\n",
    "\n",
    "\n",
    "    patch_counts = [np.shape(k)[1] for k in rscs]        \n",
    "#     patch_counts[0] = patch_counts[0] - 1   \n",
    "    adds = [1] + patch_counts\n",
    "    adds = np.cumsum(adds)\n",
    "#     storage[\"img\"] = np.ones([sum(patch_counts),patch_size,patch_size,3],dtype=np.uint8)\n",
    "#     storage[\"mask\"] = np.ones([sum(patch_counts),patch_size,patch_size],dtype=np.uint8)\n",
    "\n",
    "    for index, wsi_img in tqdm.tqdm(enumerate(osis)):\n",
    "        img_label = grade_key[wsi_img['img_fname'].split('/')[-1]]\n",
    "        for rcidx in range(0,patch_counts[index]-1,100):            \n",
    "\n",
    "            img = wsi_img.get_tile(desired_mpp=model_mpp,coords=(rscs[index][0][rcidx],rscs[index][1][rcidx]),wh=(patch_size,patch_size))        \n",
    "            print(wsi_img['img_fname'].split('/')[-1])\n",
    "            print(img_label)\n",
    "            plt.imshow(img)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T21:15:58.383796Z",
     "start_time": "2020-04-07T20:13:01.544Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for index, wsi_img in tqdm.tqdm(enumerate(osis)):\n",
    "        img_label = grade_key[wsi_img['img_fname'].split('/')[-1]]\n",
    "        for rcidx in range(0,patch_counts[index]-1,100):            \n",
    "\n",
    "            img = wsi_img.get_tile(desired_mpp=model_mpp,coords=(rscs[index][0][rcidx],rscs[index][1][rcidx]),wh=(patch_size,patch_size))        \n",
    "            print(wsi_img['img_fname'].split('/')[-1])\n",
    "            print(img_label)\n",
    "            plt.imshow(img)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "useful reference\n",
    "http://machinelearninguru.com/deep_learning/data_preparation/hdf5/hdf5.html"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
